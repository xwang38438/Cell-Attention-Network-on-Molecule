{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from models.can.can import CAN\n",
    "from models.utils.sparse import from_sparse\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"data/qm9_test_cell_complex.pkl\", \"rb\") as f:\n",
    "    cc_list = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cell_loader import CCDataset\n",
    "dataset = CCDataset(cc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_0_list = [data[0] for data in dataset]\n",
    "x_1_list = [data[1] for data in dataset]\n",
    "y_list = [random.choice([0, 1]) for _ in range(30)]\n",
    "\n",
    "lower_neighborhood_list = []\n",
    "upper_neighborhood_list = []\n",
    "adjacency_0_list = []\n",
    "\n",
    "for cell_complex in cc_list:\n",
    "    adjacency_0 = cell_complex.adjacency_matrix(rank=0)\n",
    "    adjacency_0 = torch.from_numpy(adjacency_0.todense()).to_sparse()\n",
    "    adjacency_0_list.append(adjacency_0)\n",
    "\n",
    "    lower_neighborhood_t = cell_complex.down_laplacian_matrix(rank=1, signed=False)\n",
    "    lower_neighborhood_t = from_sparse(lower_neighborhood_t)\n",
    "    lower_neighborhood_list.append(lower_neighborhood_t)\n",
    "\n",
    "    try:\n",
    "        upper_neighborhood_t = cell_complex.up_laplacian_matrix(rank=1, signed=False)\n",
    "        upper_neighborhood_t = from_sparse(upper_neighborhood_t)\n",
    "    except:\n",
    "        upper_neighborhood_t = np.zeros(\n",
    "            (lower_neighborhood_t.shape[0], lower_neighborhood_t.shape[0])\n",
    "        )\n",
    "        upper_neighborhood_t = torch.from_numpy(upper_neighborhood_t).to_sparse()\n",
    "\n",
    "    upper_neighborhood_list.append(upper_neighborhood_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels_0 = x_0_list[0].shape[-1]\n",
    "in_channels_1 = x_1_list[0].shape[-1]\n",
    "#in_channels_2 = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_channels_0, in_channels_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CAN(\n",
    "    in_channels_0,\n",
    "    in_channels_1,\n",
    "    16,\n",
    "    dropout=0.5,\n",
    "    heads=3,\n",
    "    num_classes=2,\n",
    "    n_layers=2,\n",
    "    att_lift=True,\n",
    ")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CAN(\n",
       "  (lift_layer): MultiHeadLiftLayer(\n",
       "    (lifts): LiftLayer()\n",
       "  )\n",
       "  (layers): ModuleList(\n",
       "    (0): CANLayer(\n",
       "      (lower_att): MultiHeadCellAttention_v2(\n",
       "        (att_activation): LeakyReLU(negative_slope=0.2)\n",
       "        (lin_src): Linear(in_features=7, out_features=48, bias=False)\n",
       "        (lin_dst): Linear(in_features=7, out_features=48, bias=False)\n",
       "      )\n",
       "      (upper_att): MultiHeadCellAttention_v2(\n",
       "        (att_activation): LeakyReLU(negative_slope=0.2)\n",
       "        (lin_src): Linear(in_features=7, out_features=48, bias=False)\n",
       "        (lin_dst): Linear(in_features=7, out_features=48, bias=False)\n",
       "      )\n",
       "      (lin): Linear(in_features=7, out_features=48, bias=False)\n",
       "      (aggregation): Aggregation()\n",
       "    )\n",
       "    (1): CANLayer(\n",
       "      (lower_att): MultiHeadCellAttention_v2(\n",
       "        (att_activation): LeakyReLU(negative_slope=0.2)\n",
       "        (lin_src): Linear(in_features=48, out_features=48, bias=False)\n",
       "        (lin_dst): Linear(in_features=48, out_features=48, bias=False)\n",
       "      )\n",
       "      (upper_att): MultiHeadCellAttention_v2(\n",
       "        (att_activation): LeakyReLU(negative_slope=0.2)\n",
       "        (lin_src): Linear(in_features=48, out_features=48, bias=False)\n",
       "        (lin_dst): Linear(in_features=48, out_features=48, bias=False)\n",
       "      )\n",
       "      (lin): Linear(in_features=48, out_features=48, bias=False)\n",
       "      (aggregation): Aggregation()\n",
       "    )\n",
       "    (2): PoolLayer(\n",
       "      (signal_pool_activation): Sigmoid()\n",
       "    )\n",
       "  )\n",
       "  (lin_0): Linear(in_features=48, out_features=128, bias=True)\n",
       "  (lin_1): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crit = torch.nn.CrossEntropyLoss()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.3\n",
    "x_1_train, x_1_test = train_test_split(x_1_list, test_size=test_size, shuffle=False)\n",
    "x_0_train, x_0_test = train_test_split(x_0_list, test_size=test_size, shuffle=False)\n",
    "lower_neighborhood_train, lower_neighborhood_test = train_test_split(\n",
    "    lower_neighborhood_list, test_size=test_size, shuffle=False\n",
    ")\n",
    "upper_neighborhood_train, upper_neighborhood_test = train_test_split(\n",
    "    upper_neighborhood_list, test_size=test_size, shuffle=False\n",
    ")\n",
    "adjacency_0_train, adjacency_0_test = train_test_split(\n",
    "    adjacency_0_list, test_size=test_size, shuffle=False\n",
    ")\n",
    "y_train, y_test = train_test_split(y_list, test_size=test_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 loss: 0.7065 Train_acc: 0.5714\n",
      "Test_acc: 0.5556\n",
      "Epoch: 2 loss: 0.7037 Train_acc: 0.5714\n",
      "Test_acc: 0.5556\n",
      "Epoch: 3 loss: 0.6979 Train_acc: 0.5714\n",
      "Test_acc: 0.5556\n",
      "Epoch: 4 loss: 0.6853 Train_acc: 0.5714\n",
      "Test_acc: 0.5556\n"
     ]
    }
   ],
   "source": [
    "test_interval = 1\n",
    "num_epochs = 4\n",
    "for epoch_i in range(1, num_epochs + 1):\n",
    "    epoch_loss = []\n",
    "    num_samples = 0\n",
    "    correct = 0\n",
    "    model.train()\n",
    "    for x_0, x_1, adjacency, lower_neighborhood, upper_neighborhood, y in zip(\n",
    "        x_0_train,\n",
    "        x_1_train,\n",
    "        adjacency_0_train,\n",
    "        lower_neighborhood_train,\n",
    "        upper_neighborhood_train,\n",
    "        y_train,\n",
    "    ):\n",
    "        x_0 = x_0.float().to(device)\n",
    "        x_1, y = x_1.float().to(device), torch.tensor(y, dtype=torch.long).to(device)\n",
    "        adjacency = adjacency.float().to(device)\n",
    "        lower_neighborhood, upper_neighborhood = lower_neighborhood.float().to(\n",
    "            device\n",
    "        ), upper_neighborhood.float().to(device)\n",
    "        opt.zero_grad()\n",
    "        y_hat = model(x_0, x_1, adjacency, lower_neighborhood, upper_neighborhood)\n",
    "        #print('notice')\n",
    "        loss = crit(y_hat, y)\n",
    "        #print(loss)\n",
    "        correct += (y_hat.argmax() == y).sum().item()\n",
    "        num_samples += 1\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        epoch_loss.append(loss.item())\n",
    "    train_acc = correct / num_samples\n",
    "    print(\n",
    "        f\"Epoch: {epoch_i} loss: {np.mean(epoch_loss):.4f} Train_acc: {train_acc:.4f}\",\n",
    "        flush=True,\n",
    "    )\n",
    "    if epoch_i % test_interval == 0:\n",
    "        with torch.no_grad():\n",
    "            num_samples = 0\n",
    "            correct = 0\n",
    "            for x_0, x_1, adjacency, lower_neighborhood, upper_neighborhood, y in zip(\n",
    "                x_0_test,\n",
    "                x_1_test,\n",
    "                adjacency_0_test,\n",
    "                lower_neighborhood_test,\n",
    "                upper_neighborhood_test,\n",
    "                y_test,\n",
    "            ):\n",
    "                x_0 = x_0.float().to(device)\n",
    "                x_1, y = x_1.float().to(device), torch.tensor(y, dtype=torch.long).to(\n",
    "                    device\n",
    "                )\n",
    "                adjacency = adjacency.float().to(device)\n",
    "                lower_neighborhood, upper_neighborhood = lower_neighborhood.float().to(\n",
    "                    device\n",
    "                ), upper_neighborhood.float().to(device)\n",
    "                y_hat = model(\n",
    "                    x_0, x_1, adjacency, lower_neighborhood, upper_neighborhood\n",
    "                )\n",
    "                #print(y_hat)\n",
    "                correct += (y_hat.argmax() == y).sum().item()\n",
    "                num_samples += 1\n",
    "            test_acc = correct / num_samples\n",
    "            print(f\"Test_acc: {test_acc:.4f}\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.can.can_layer import MultiHeadCellAttention_v2\n",
    "\n",
    "mh = MultiHeadCellAttention_v2(in_channels=3, out_channels = 32, \n",
    "                               heads = 3, concat= True,\n",
    "                               att_activation= torch.nn.ReLU(), aggr_func='sum',\n",
    "                               dropout=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(indices=tensor([[5, 5, 5, 7, 7, 7, 9, 9, 9],\n",
      "                       [5, 7, 9, 5, 7, 9, 5, 7, 9]]),\n",
      "       values=tensor([1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
      "       size=(18, 18), nnz=9, layout=torch.sparse_coo)\n",
      "CellView([Cell((2, 3, 4))])\n",
      "18\n",
      "torch.Size([18, 96])\n"
     ]
    }
   ],
   "source": [
    "i = 17\n",
    "print(upper_neighborhood_list[i])\n",
    "print(cc_list[i].cells)\n",
    "print(cc_list[i].number_of_edges())\n",
    "print(mh(x_1_list[i], upper_neighborhood_list[i]).shape)\n",
    "#print(mh(x_1_list[i], lower_neighborhood_list[i]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9])\n",
      "torch.Size([9])\n",
      "torch.Size([18, 96])\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "(target_index_i,source_index_j,) = upper_neighborhood_list[i].indices() \n",
    "print(target_index_i.shape)\n",
    "print(source_index_j.shape)\n",
    "print(mh(x_1_list[i], upper_neighborhood_list[i]).shape)\n",
    "print(upper_neighborhood_list[i].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_edges: 18\n"
     ]
    }
   ],
   "source": [
    "class CustomTensor:\n",
    "    def __init__(self, tensor, n_edges=None):\n",
    "        self.tensor = tensor\n",
    "        self.n_edges = n_edges\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        # Delegate attribute access to the tensor\n",
    "        return getattr(self.tensor, name)\n",
    "\n",
    "    # If you need to support specific tensor methods, you might need to explicitly define them\n",
    "    def to(self, *args, **kwargs):\n",
    "        # Example of delegating a method call to the tensor\n",
    "        self.tensor = self.tensor.to(*args, **kwargs)\n",
    "        return self\n",
    "\n",
    "# Usage\n",
    "your_tensor = torch.tensor([1, 2, 3])\n",
    "n_edges = 18\n",
    "custom_tensor = CustomTensor(your_tensor, n_edges=n_edges)\n",
    "\n",
    "# Tensor operations\n",
    "result = custom_tensor.tensor + torch.tensor([1, 1, 1])\n",
    "\n",
    "# Accessing custom attribute\n",
    "print(\"n_edges:\", custom_tensor.n_edges)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 3])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def scatter_add_(self, index, src, num_edges=None):\n",
    "    if num_edges is None:\n",
    "        num_edges = src.numel()\n",
    "\n",
    "    # Check if dimensions match and num_edges is within the valid range\n",
    "    if self.dim() != src.dim() or self.dim() != index.dim():\n",
    "        raise ValueError(\"All tensors must have the same number of dimensions\")\n",
    "    if num_edges > src.numel():\n",
    "        raise ValueError(\"num_edges is larger than the number of elements in src\")\n",
    "\n",
    "    # Iterate and add values\n",
    "    for n in range(num_edges):\n",
    "        # Convert flat index to 3D index\n",
    "        i, j, k = np.unravel_index(n, src.shape)\n",
    "        self[index[i][j][k]][j][k] += src[i][j][k]\n",
    "\n",
    "    return self\n",
    "\n",
    "# Example usage\n",
    "self_tensor = torch.zeros(5, 3, 3)  # Adjust the size as needed\n",
    "index_tensor = torch.randint(0, 5, (2, 3, 3))\n",
    "src_tensor = torch.randn(2, 3, 3)\n",
    "\n",
    "scatter_add_(self_tensor, index_tensor, src_tensor).shape\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tmx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
